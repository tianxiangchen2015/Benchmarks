{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle, gzip\n",
    "\n",
    "from neon import logger as neon_logger\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "from neon.data import MNIST\n",
    "from neon.initializers import Gaussian, GlorotUniform\n",
    "from neon.layers import Affine, BranchNode, Multicost, Tree, GeneralizedCost\n",
    "from neon.models import Model\n",
    "from neon.optimizers import RMSProp\n",
    "from neon.transforms import Rectlin, Logistic, Softmax\n",
    "from neon.transforms import CrossEntropyMulti, Misclassification\n",
    "from neon.util.argparser import NeonArgparser\n",
    "from neon.data import ArrayIterator\n",
    "from neon.backends import gen_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a number of initial variables for use with baseline\n",
    "NUM_TASKS = 3; # number of learning tasks (for multi-task learning)\n",
    "NUM_FOLDS = 10; # number of folds for training (main cross validation loop)\n",
    "NUM_EPOCH = 5; # number of epochs\n",
    "\n",
    "\n",
    "\n",
    "truth_a_arr = []\n",
    "pred_a_arr = []\n",
    "\n",
    "truth_b_arr = []\n",
    "pred_b_arr = []\n",
    "\n",
    "truth_c_arr = []\n",
    "pred_c_arr = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fold in range( NUM_FOLDS ):\n",
    "\n",
    "    features_train = []\n",
    "    labels_train = []\n",
    "    truths_train = []\n",
    "\n",
    "    features_test = []\n",
    "    labels_test = []\n",
    "    truths_test = []\n",
    "\n",
    "    n_out = []\n",
    "\n",
    "    for task in range( NUM_TASKS ):\n",
    "        file_post = '.' + str(task) + '.' + str(fold) + '.pkl.gz'\n",
    "        fname_train = 'train/train' + file_post; \n",
    "        fname_test  = 'test/test' + file_post; \n",
    "\n",
    "        with gzip.open( fname_train, 'rb' ) as f:\n",
    "            feature_train, label_train = cPickle.load( f )\n",
    "\n",
    "        with gzip.open( fname_test, 'rb') as f:\n",
    "            feature_test, label_test = cPickle.load( f )\n",
    "\n",
    "        features_train.append( feature_train )\n",
    "        labels_train.append( label_train )\n",
    "\n",
    "        features_test.append( feature_test )\n",
    "        labels_test.append( label_test )\n",
    "\n",
    "        mv = numpy.max( label_train )\n",
    "        truth_train = numpy.zeros( ( len( label_train ), mv + 1 ) )\n",
    "        for i in range( len( label_train ) ):\n",
    "            truth_train[ i, label_train[ i ] ] = 1\n",
    "\n",
    "        truths_train.append( truth_train )\n",
    "\n",
    "        mv = numpy.max( label_test )\n",
    "        truth_test = numpy.zeros( ( len( label_test ), mv + 1 ) )\n",
    "        for i in range( len( label_test ) ):\n",
    "            truth_test[ i, label_test[ i ] ] = 1\n",
    "\n",
    "        truths_test.append( truth_test )\n",
    "\n",
    "        n_out.append( mv + 1 )\n",
    "\n",
    "    flen = len( feature_train[ 0 ] ); # input feature length is set to 400 for now based on the training examples available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_out = np.array(n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.backends import gen_backend\n",
    "be = gen_backend(backend='cpu',batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_t1 = ArrayIterator(X=features_train[0], y=labels_train[0], nclass=n_out[0])\n",
    "train_t2 = ArrayIterator(X=features_train[1], y=labels_train[1], nclass=n_out[1])\n",
    "train_t3 = ArrayIterator(X=features_train[2], y=labels_train[2], nclass=n_out[2])\n",
    "\n",
    "test_t1 = ArrayIterator(X=features_test[0], y=labels_test[0], nclass=n_out[0])\n",
    "test_t2 = ArrayIterator(X=features_test[1], y=labels_test[1], nclass=n_out[1])\n",
    "test_t3 = ArrayIterator(X=features_test[2], y=labels_test[2], nclass=n_out[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1 = BranchNode(name='b1')\n",
    "b2 = BranchNode(name='b2')\n",
    "init = GlorotUniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = [Affine(nout=flen, name=\"t1_input\", activation=Rectlin(), init=init), \n",
    "      b1,\n",
    "      Affine(nout=flen, name=\"share\", activation=Rectlin(), init=init),\n",
    "      b2,\n",
    "      Affine(nout=flen, name=\"t1_3\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=256, name=\"t1_4\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=n_out[0], name=\"t2_out\", activation=Rectlin(), init=init)]\n",
    "p2 = [Affine(nout=flen, name=\"t2_input\", activation=Rectlin(), init=init),\n",
    "     b1,\n",
    "     Affine(nout=flen, name=\"share\", activation=Rectlin(), init=init),\n",
    "     b2, \n",
    "      Affine(nout=flen, name=\"t2_3\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=256, name=\"t2_4\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=n_out[1], name=\"t2_out\", activation=Rectlin(), init=init)]\n",
    "p3 = [Affine(nout=flen, name=\"t3_input\", activation=Rectlin(), init=init),\n",
    "     b1,\n",
    "     Affine(nout=flen, name=\"share\", activation=Rectlin(), init=init),\n",
    "     b2, \n",
    "      Affine(nout=flen, name=\"t3_3\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=256, name=\"t3_4\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=n_out[2], name=\"t3_out\", activation=Rectlin(), init=init)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_1 = Model(layers=p1)\n",
    "model_2 = Model(layers=p2)\n",
    "model_3 = Model(layers=p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = RMSProp(learning_rate=0.001)\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti())\n",
    "                        \n",
    "callbacks_1 = Callbacks(model_1, eval_set=test_t1,\n",
    "                      eval_freq=NUM_EPOCH)\n",
    "callbacks_2 = Callbacks(model_2, eval_set=test_t2,\n",
    "                      eval_freq=NUM_EPOCH)\n",
    "callbacks_3 = Callbacks(model_3, eval_set=test_t3,\n",
    "                      eval_freq=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   [Train |████████████████████|  120/120  batches, 0.01 cost, 1.13s]\n",
      "Epoch 1   [Train |████████████████████|  120/120  batches, 0.04 cost, 1.23s]\n",
      "Epoch 2   [Train |████████████████████|  120/120  batches, 0.06 cost, 1.23s]\n",
      "Epoch 3   [Train |████████████████████|  120/120  batches, 0.04 cost, 1.13s]\n",
      "Epoch 4   [Train |████████████████████|  120/120  batches, 0.03 cost, 1.09s] [CrossEntropyMulti Loss 1.44, 0.02s]\n",
      "Epoch 0   [Train |████████████████████|  120/120  batches, 0.01 cost, 1.13s]\n",
      "Epoch 1   [Train |████████████████████|  120/120  batches, 0.00 cost, 1.34s]\n",
      "Epoch 2   [Train |████████████████████|  120/120  batches, 0.01 cost, 1.37s]\n",
      "Epoch 3   [Train |████████████████████|  120/120  batches, 0.01 cost, 1.31s]\n",
      "Epoch 4   [Train |████████████████████|  120/120  batches, 0.02 cost, 1.31s] [CrossEntropyMulti Loss 25.95, 0.01s]\n",
      "Epoch 0   [Train |████████████████████|  120/120  batches, 50.00 cost, 1.27s]\n",
      "Epoch 1   [Train |████████████████████|  120/120  batches, 50.00 cost, 1.38s]\n",
      "Epoch 2   [Train |████████████████████|  120/120  batches, 50.00 cost, 1.39s]\n",
      "Epoch 3   [Train |████████████████████|  120/120  batches, 50.00 cost, 1.36s]\n",
      "Epoch 4   [Train |████████████████████|  120/120  batches, 50.00 cost, 1.42s] [CrossEntropyMulti Loss 39.04, 0.02s]\n"
     ]
    }
   ],
   "source": [
    "model_1.fit(train_t1, optimizer=optimizer, \n",
    "            cost=cost, \n",
    "            callbacks=callbacks_1, num_epochs=NUM_EPOCH)\n",
    "model_2.fit(train_t2, optimizer=optimizer, cost=cost, \n",
    "            callbacks=callbacks_2, num_epochs=NUM_EPOCH)\n",
    "model_3.fit(train_t3, optimizer=optimizer, cost=cost, \n",
    "            callbacks=callbacks_3, num_epochs=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
