{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle, gzip\n",
    "\n",
    "from neon import logger as neon_logger\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "from neon.data import MNIST\n",
    "from neon.initializers import Gaussian, GlorotUniform\n",
    "from neon.layers import Affine, BranchNode, Multicost, Tree, GeneralizedCost, SingleOutputTree\n",
    "from neon.models import Model\n",
    "from neon.optimizers import RMSProp\n",
    "from neon.transforms import Rectlin, Logistic, Softmax\n",
    "from neon.transforms import CrossEntropyMulti, Misclassification\n",
    "from neon.util.argparser import NeonArgparser\n",
    "from neon.data import ArrayIterator\n",
    "from neon.backends import gen_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.backends import gen_backend\n",
    "be = gen_backend(backend='cpu',batch_size=10)\n",
    "train = ArrayIterator(X=[features_train[0], features_train[1]], \n",
    "                      y=labels_train[0], nclass=n_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neon.data import NervanaDataIterator\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import os\n",
    "\n",
    "class SVHN(NervanaDataIterator):\n",
    "\n",
    "    def __init__(self, X, Y, nclass):\n",
    "\n",
    "        # Load the numpy data into some variables. We divide the image by 255 to normalize the values\n",
    "        # between 0 and 1.\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.nclass_t1 = nclass[0]\n",
    "        self.nclass_t2 = nclass[1]\n",
    "        self.nclass_t3 = nclass[2]\n",
    "#         self.shape = lshape  # shape of the input data (e.g. for images, (C, H, W))\n",
    "\n",
    "        # 1. assign some required and useful attributes\n",
    "        self.start = 0  # start at zero\n",
    "        self.ndata = self.X[0].shape[0]  # number of images in X (hint: use X.shape)\n",
    "        self.nfeatures = self.X[0].shape[1]  # number of features in X (hint: use X.shape)\n",
    "        self.Y_t1 = onehot_gen(self.Y[0], self.ndata, self.nclass_t1)\n",
    "        self.Y_t2 = onehot_gen(self.Y[1], self.ndata, self.nclass_t2)\n",
    "        self.Y_t3 = onehot_gen(self.Y[2], self.ndata, self.nclass_t3)\n",
    "\n",
    "        # number of minibatches per epoch\n",
    "        # to calculate this, use the batchsize, which is stored in self.be.bsz\n",
    "        self.nbatches = self.ndata/self.be.bsz \n",
    "        \n",
    "        \n",
    "        # 2. allocate memory on the GPU for a minibatch's worth of data.\n",
    "        # (e.g. use `self.be` to access the backend.). See the backend documentation.\n",
    "        # to get the minibatch size, use self.be.bsz\n",
    "        # hint: X should have shape (# features, mini-batch size)\n",
    "        # hint: use some of the attributes previously defined above\n",
    "        self.dev_X_t1 = self.be.zeros((self.nfeatures, self.be.bsz))\n",
    "        self.dev_X_t2 = self.be.zeros((self.nfeatures, self.be.bsz))\n",
    "        self.dev_X_t3 = self.be.zeros((self.nfeatures, self.be.bsz))\n",
    "        self.dev_Y_t1 = self.be.zeros((self.Y[0].shape[1], self.be.bsz))\n",
    "        self.dev_Y_t2 = self.be.zeros((self.Y[1].shape[1], self.be.bsz))\n",
    "        self.dev_Y_t3 = self.be.zeros((self.Y[2].shape[1], self.be.bsz))\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.start = 0\n",
    "        \n",
    "    def onehot_gen(z, s, n):\n",
    "        self.b = np.zeros((s, n))\n",
    "        self.b[np.arange(s), z] = 1\n",
    "        return b    \n",
    "    def __iter__(self):\n",
    "        # 3. loop through minibatches in the dataset\n",
    "        for index in range(self.start, self.ndata, self.be.bsz):\n",
    "            # 3a. grab the right slice from the numpy arrays\n",
    "            inputs_t1 = self.X[0][index:(index + self.be.bsz), :]\n",
    "            targets_t1 = self.Y_t1[index:(index + self.be.bsz), :]\n",
    "            inputs_t2 = self.X[1][index:(index + self.be.bsz), :]\n",
    "            targets_t2 = self.Y_t2[index:(index + self.be.bsz), :]\n",
    "            inputs_t3 = self.X[2][index:(index + self.be.bsz), :]\n",
    "            targets_t3 = self.Y_t3[index:(index + self.be.bsz), :]\n",
    "            \n",
    "            \n",
    "            # The arrays X and Y data are in shape (batch_size, num_features),\n",
    "            # but the iterator needs to return data with shape (num_features, batch_size).\n",
    "            # here we transpose the data, and then store it as a contiguous array. \n",
    "            # numpy arrays need to be contiguous before being loaded onto the GPU.\n",
    "            inputs_t1 = np.ascontiguousarray(inputs_t1.T)\n",
    "            targets_t1 = np.ascontiguousarray(targets_t1.T)\n",
    "            inputs_t2 = np.ascontiguousarray(inputs_t2.T)\n",
    "            targets_t2 = np.ascontiguousarray(targets_t2.T)\n",
    "            inputs_t3 = np.ascontiguousarray(inputs_t3.T)\n",
    "            targets_t3 = np.ascontiguousarray(targets_t3.T)\n",
    "                        \n",
    "            # here we test your implementation\n",
    "            # your slice has to have the same shape as the GPU tensors you allocated\n",
    "#             assert inputs[0].shape == self.dev_X_t1.shape, \\\n",
    "#                    \"inputs has shape {}, but dev_X is {}\".format(inputs.shape, self.dev_X.shape)\n",
    "#             assert targets[0].shape == self.dev_Y_t1.shape, \\\n",
    "#                    \"targets has shape {}, but dev_Y is {}\".format(targets.shape, self.dev_Y.shape)\n",
    "            \n",
    "            # 3b. transfer from numpy arrays to device\n",
    "            # - use the GPU memory buffers allocated previously,\n",
    "            #    and call the myTensorBuffer.set() function. \n",
    "            self.dev_X_t1.set(inputs_t1)\n",
    "            self.dev_Y_t1.set(targets_t1)\n",
    "            self.dev_X_t2.set(inputs_t2)\n",
    "            self.dev_Y_t2.set(targets_t2)\n",
    "            self.dev_X_t3.set(inputs_t3)\n",
    "            self.dev_Y_t3.set(targets_t3)\n",
    "            \n",
    "            # 3c. yield a tuple of the device tensors.\n",
    "            # X should be of shape (num_features, batch_size)\n",
    "            # Y should be of shape (4, batch_size)\n",
    "            yield ((self.dev_X_t1, self.dev_X_t2, self.dev_X_t3 ),\n",
    "                   (self.dev_Y_t1, self.dev_Y_t2, self.dev_Y_t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a number of initial variables for use with baseline\n",
    "NUM_TASKS = 3; # number of learning tasks (for multi-task learning)\n",
    "NUM_FOLDS = 10; # number of folds for training (main cross validation loop)\n",
    "NUM_EPOCH = 5; # number of epochs\n",
    "\n",
    "\n",
    "\n",
    "truth_a_arr = []\n",
    "pred_a_arr = []\n",
    "\n",
    "truth_b_arr = []\n",
    "pred_b_arr = []\n",
    "\n",
    "truth_c_arr = []\n",
    "pred_c_arr = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fold in range( NUM_FOLDS ):\n",
    "\n",
    "    features_train = []\n",
    "    labels_train = []\n",
    "    truths_train = []\n",
    "\n",
    "    features_test = []\n",
    "    labels_test = []\n",
    "    truths_test = []\n",
    "\n",
    "    n_out = []\n",
    "\n",
    "    for task in range( NUM_TASKS ):\n",
    "        file_post = '.' + str(task) + '.' + str(fold) + '.pkl.gz'\n",
    "        fname_train = 'train/train' + file_post; \n",
    "        fname_test  = 'test/test' + file_post; \n",
    "        with gzip.open( fname_train, 'rb' ) as f:\n",
    "            feature_train, label_train = cPickle.load( f )\n",
    "\n",
    "        with gzip.open( fname_test, 'rb') as f:\n",
    "            feature_test, label_test = cPickle.load( f )\n",
    "\n",
    "        features_train.append( feature_train )\n",
    "        labels_train.append( label_train )\n",
    "\n",
    "        features_test.append( feature_test )\n",
    "        labels_test.append( label_test )\n",
    "\n",
    "        mv = np.max( label_train )\n",
    "        truth_train = np.zeros( ( len( label_train ), mv + 1 ) )\n",
    "        for i in range( len( label_train ) ):\n",
    "            truth_train[ i, label_train[ i ] ] = 1\n",
    "\n",
    "        truths_train.append( truth_train )\n",
    "\n",
    "        mv = np.max( label_test )\n",
    "        truth_test = np.zeros( ( len( label_test ), mv + 1 ) )\n",
    "        for i in range( len( label_test ) ):\n",
    "            truth_test[ i, label_test[ i ] ] = 1\n",
    "\n",
    "        truths_test.append( truth_test )\n",
    "\n",
    "        n_out.append( mv + 1 )\n",
    "\n",
    "    flen = len( feature_train[ 0 ] ); # input feature length is set to 400 for now based on the training examples available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 400)\n",
      "(1200, 400)\n",
      "(1200, 400)\n"
     ]
    }
   ],
   "source": [
    "for x in features_train:\n",
    "    print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 1 1 1]\n",
      "(1200,)\n",
      "(1200, 2)\n"
     ]
    }
   ],
   "source": [
    "print labels_train[0]\n",
    "a = onehot_gen(labels_train[0], 1200, n_out[0])\n",
    "print labels_train[0].shape\n",
    "print a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPUTensor(base 0x105069030) name:None shape:(3, 3, 3) dtype:float32 strides:(36, 12, 4) is_c_contiguous:True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be.zeros((3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-75f887a64579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVHN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-c294d713bfda>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, Y, nclass)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_X_t2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_X_t3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_Y_t1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_Y_t2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_Y_t3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "train = SVHN(features_train, labels_train, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_t1 = ArrayIterator(X=features_train[0], y=labels_train[0], nclass=n_out[0])\n",
    "train_t2 = ArrayIterator(X=features_train[1], y=labels_train[1], nclass=n_out[1])\n",
    "train_t3 = ArrayIterator(X=features_train[2], y=labels_train[2], nclass=n_out[2])\n",
    "\n",
    "test_t1 = ArrayIterator(X=features_test[0], y=labels_test[0], nclass=n_out[0])\n",
    "test_t2 = ArrayIterator(X=features_test[1], y=labels_test[1], nclass=n_out[1])\n",
    "test_t3 = ArrayIterator(X=features_test[2], y=labels_test[2], nclass=n_out[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1 = BranchNode(name='b1')\n",
    "b2 = BranchNode(name='b2')\n",
    "init = GlorotUniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = [Affine(nout=flen, name=\"t1_input\", activation=Rectlin(), init=init), \n",
    "      b1,\n",
    "      Affine(nout=flen, name=\"share\", activation=Rectlin(), init=init),\n",
    "      b2,\n",
    "      Affine(nout=flen, name=\"t1_3\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=256, name=\"t1_4\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=n_out[0], name=\"t2_out\", activation=Rectlin(), init=init)]\n",
    "p2 = [Affine(nout=flen, name=\"t1_input\", activation=Rectlin(), init=init), \n",
    "      b1,\n",
    "      Affine(nout=flen, name=\"share\", activation=Rectlin(), init=init),\n",
    "      b2, \n",
    "      Affine(nout=flen, name=\"t2_3\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=256, name=\"t2_4\", activation=Rectlin(), init=init),\n",
    "      Affine(nout=n_out[1], name=\"t2_out\", activation=Rectlin(), init=init)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(layers=SingleOutputTree([p1, p2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = RMSProp(learning_rate=0.001)\n",
    "cost = Multicost(costs=[GeneralizedCost(costfunc=CrossEntropyMulti(usebits=True))])\n",
    "                        \n",
    "callbacks_1 = Callbacks(model_1, eval_set=test_t1, eval_freq=NUM_EPOCH)\n",
    "callbacks_2 = Callbacks(model_2, eval_set=test_t2, eval_freq=NUM_EPOCH)\n",
    "callbacks_3 = Callbacks(model_3, eval_set=test_t3, eval_freq=NUM_EPOCH)\n",
    "\n",
    "callbacks_1 = Callbacks(model_1, eval_set=test_t1, eval_freq=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost1 = CrossEntropyMulti(usebits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-8301921c4af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#             callbacks=callbacks_3, num_epochs=NUM_EPOCH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model_4.fit(train_t1, optimizer=optimizer, cost=cost, callbacks=callbacks_1, \n\u001b[0;32m----> 8\u001b[0;31m             num_epochs=NUM_EPOCH)\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/neon-1.8.2-py2.7.egg/neon/models/model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, cost, optimizer, num_epochs, callbacks)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/neon-1.8.2-py2.7.egg/neon/models/model.pyc\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, dataset, cost)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/neon-1.8.2-py2.7.egg/neon/layers/layer.pyc\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, in_obj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         self.deltas = self.be.iobuf(in_obj.out_shape,\n\u001b[1;32m   1917\u001b[0m                                     \u001b[0mparallelism\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m                                     persist_values=False)\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/neon-1.8.2-py2.7.egg/neon/backends/backend.pyc\u001b[0m in \u001b[0;36miobuf\u001b[0;34m(self, dim0, x, dtype, name, persist_values, shared, parallelism)\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mout_tsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbufshape\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0mout_tsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mout_tsr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/neon-1.8.2-py2.7.egg/neon/backends/nervanacpu.pyc\u001b[0m in \u001b[0;36mempty\u001b[0;34m(self, shape, dtype, name, persist_values, parallel, distributed)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "# model_1.fit(train_t1, optimizer=optimizer, cost=cost, callbacks=callbacks_1, \n",
    "#             num_epochs=1)\n",
    "# model_2.fit(train_t2, optimizer=optimizer, cost=cost, \n",
    "#             callbacks=callbacks_2, num_epochs=NUM_EPOCH)\n",
    "# model_3.fit(train_t3, optimizer=optimizer, cost=cost, \n",
    "#             callbacks=callbacks_3, num_epochs=NUM_EPOCH)\n",
    "model_4.fit(train_t1, optimizer=optimizer, cost=cost, callbacks=callbacks_1, \n",
    "            num_epochs=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdict = model_1.get_description(get_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdict2 = model_2.get_description(get_weights=True)\n",
    "pdict3 = model_3.get_description(get_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_gen(z, s, n):\n",
    "    b = np.zeros((s, n))\n",
    "    b[np.arange(s), z] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "a = [0,1,1,3,2]\n",
    "b = onehot_gen(a, len(a), 4)\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
