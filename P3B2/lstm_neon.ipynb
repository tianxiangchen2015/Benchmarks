{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from neon.layers import GeneralizedCost, LSTM, Affine\n",
    "from neon.models import Model\n",
    "from neon.optimizers import RMSProp\n",
    "from neon.transforms import Logistic, Tanh, Softmax, CrossEntropyMulti\n",
    "from neon.callbacks.callbacks import Callbacks\n",
    "from neon.util.argparser import NeonArgparser\n",
    "from neon.data import Text\n",
    "from neon.initializers import GlorotUniform, Uniform, Orthonormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import cPickle\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create neon backend, batch_size=20\n",
    "from neon.backends import gen_backend\n",
    "be = gen_backend(backend='cpu',batch_size=20)\n",
    "rnn_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use neon.data.Text data iterator. It will create vocab and one-hot representation of the input.\n",
    "Document link: https://neon.nervanasys.com/index.html/generated/neon.data.text.Text.html#neon.data.text.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Text iterator. Timestep = 20\n",
    "from neon.data import Text\n",
    "path = '/Users/tgn/Desktop/pilot/Benchmarks/P3B2/raw_text_upper.txt'\n",
    "data = Text(20, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create layers\n",
    "init_orthonormal = Orthonormal()\n",
    "layers = [LSTM(output_size=rnn_size, init=init_glorot, activation=Tanh(),gate_activation=Tanh(),\n",
    "               init_inner=init_orthonormal),\n",
    "         Affine(len(data.vocab), init=init_glorot, activation=Softmax())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = RMSProp()\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti(usebits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the model to \"neon_lstm_model_upper.pickle\"\n",
    "from neon.callbacks import Callbacks\n",
    "from neon.models import Model\n",
    "model = Model(layers=layers)\n",
    "num_epochs = 2\n",
    "fname = \"neon_lstm_model_upper\"\n",
    "model = Model(layers=layers)\n",
    "callbacks = Callbacks(model, eval_set=data, eval_freq=num_epochs,\n",
    "                      serialize=1, save_path=fname + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   [Train |████████████████████| 7177/7177 batches, 1.53 cost, 409.97s]\n",
      "Epoch 1   [Train |████████████████████| 7177/7177 batches, 1.41 cost, 413.77s] [CrossEntropyMulti Loss 1.27, 174.36s]\n",
      "Epoch 2   [Train |████████████████████| 7177/7177 batches, 1.32 cost, 416.47s]\n",
      "Epoch 3   [Train |████████████████████| 7177/7177 batches, 1.25 cost, 414.77s] [CrossEntropyMulti Loss 1.16, 174.35s]\n",
      "Epoch 4   [Train |████████████████████| 7177/7177 batches, 1.21 cost, 413.07s]\n"
     ]
    }
   ],
   "source": [
    "model.fit(data, optimizer=optimizer, num_epochs=20, cost=cost, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(prob):\n",
    "    prob = prob / (prob.sum() + 1e-6)\n",
    "    return np.argmax(np.random.multinomial(1, prob, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize new model using saved model and generate text.\n",
    "model.be.bsz=20\n",
    "time_steps = 1\n",
    "num_predict = 1000\n",
    "\n",
    "model_new = Model(layers=layers)\n",
    "model_new.load_params('/Users/tgn/Desktop/pilot/Benchmarks/P3B2/neon_lstm_model_upper.pickle')\n",
    "model_new.initialize(dataset=(data.shape[0], time_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "seed_tokens = list('ROMEO:')\n",
    "\n",
    "x = model_new.be.zeros((len(data.vocab), 20))\n",
    "\n",
    "for s in seed_tokens:\n",
    "    x.fill(0)\n",
    "    x[data.token_to_index[s], 0] = 1\n",
    "    y = model_new.fprop(x)\n",
    "    \n",
    "for i in range(num_predict):\n",
    "    # Take last prediction and feed into next fprop\n",
    "    pred = sample(y.get()[:, -1])\n",
    "    text.append(data.index_to_token[int(pred)])\n",
    "\n",
    "    x.fill(0)\n",
    "    x[int(pred), 0] = 1\n",
    "    y = model_new.fprop(x)\n",
    "    \n",
    "neon_logger.display(''.join(seed_tokens + text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
